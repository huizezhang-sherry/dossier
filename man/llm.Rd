% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm.R
\name{extract_decisions}
\alias{extract_decisions}
\title{Extract decisions from PDF inputs via LLM}
\usage{
extract_decisions(prompt_file, pdf, file = NULL, ..., llm_model = "gemini")
}
\arguments{
\item{prompt_file}{A single string containing the prompt}

\item{pdf}{A single string specifying the path to a PDF file}

\item{file}{A single string specifying where to save the output. By default,
it saves a markdown file with the same name as the PDF file in the same directory.}

\item{...}{other arguments supplied to the LLM chat function, such as `seed`, `temperature`, etc.}

\item{llm_model}{One of `"claude"` or `"gemini"` for processing pdf documents. Default to `gemini`}
}
\value{
Writes output to the specified file.
}
\description{
The function writes a markdown file at the `file` location with the decisions
extracted from the PDF inputs via the LLM. The decisions are  formatted as a
JSON block. See the LLM prompt file
`system.file("prompt.md", package = "dossier") |> readLines()` for more
details. To setup the authentication for the LLM, please refer to the
`ellmer` package.
}
\seealso{
[clean_md]
}
